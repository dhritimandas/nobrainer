{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference_with_kwyk_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBK-IPRmOteE"
      },
      "source": [
        "# Get brain tissue parcellation using kwyk model\n",
        "\n",
        "In this notebook, we will use [kwyk](https://www.frontiersin.org/articles/10.3389/fninf.2019.00067/full) model to the get the 50 class brain parcellation. kwyk, is a bayesian model that is trained by freesurfer labels and gives an uncertainty map of predicted classes in addition to the output.\n",
        "\n",
        "In the following cells, we will:\n",
        "\n",
        "1. Get sample T1-weighted MR scans as an input image.\n",
        "2. Load a pre-trained kwyk 50 class segmentation model.\n",
        "3. Use nobrainer function to get the segmentation.\n",
        "\n",
        "## Google Colaboratory\n",
        "\n",
        "If you are using Colab, please switch your runtime to GPU. To do this, select `Runtime > Change runtime type` in the top menu. Then select GPU under `Hardware accelerator`. A GPU greatly speeds up training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piYIytZjWOYE"
      },
      "source": [
        "In this tutorial we will need to pull in external models using datalad. To support it we first install git-annex using Neurodebian.\n",
        "\n",
        "**Note: Sometimes getting the gpg key can fail. If you notice such an error, simply re-execute the cell.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVmqP-fnKEii"
      },
      "source": [
        "!wget -O- http://neuro.debian.net/lists/bionic.us-nh.full | tee /etc/apt/sources.list.d/neurodebian.sources.list \\\n",
        " && export GNUPGHOME=\"$(mktemp -d)\" \\\n",
        " && echo \"disable-ipv6\" >> ${GNUPGHOME}/dirmngr.conf \\\n",
        " && (apt-key adv --homedir $GNUPGHOME --recv-keys --keyserver hkp://pgpkeys.eu 0xA5D32F012649A5A9 \\\n",
        "|| { curl -sSL http://neuro.debian.net/_static/neuro.debian.net.asc | apt-key add -; } ) \\\n",
        " && apt-get update \\\n",
        " && apt-get install git-annex-standalone git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQAbOMrPWXKh"
      },
      "source": [
        "Let's make sure the correct version of git-annex is installed. This should be at least **8.20210223** or later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8tMBrVVKPBJ"
      },
      "source": [
        "!git-annex version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQUyby4TK7Wz"
      },
      "source": [
        "!pip install --no-cache-dir nilearn datalad datalad-osf\n",
        "!pip install --no-cache-dir nobrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05g3oduhchOS"
      },
      "source": [
        "import nobrainer\n",
        "import tensorflow as tf\n",
        "import nibabel as nib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwamsOp3XKSz"
      },
      "source": [
        "# Get a sample T1w image \n",
        "\n",
        "We use the sample dataset available through nobrainer to get our prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6BuC7rJLG30"
      },
      "source": [
        "csv_of_filepaths = nobrainer.utils.get_data()\n",
        "filepaths = nobrainer.io.read_csv(csv_of_filepaths)\n",
        "\n",
        "train_paths = filepaths[:9]\n",
        "evaluate_paths = filepaths[9:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Ue6H67YTWG"
      },
      "source": [
        "Here is an example of one of the images, with the freesurfer labels overlaid on the anatomical image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-KFMM-aYfux"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nilearn import plotting\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "plotting.plot_roi(train_paths[0][1], bg_img=train_paths[0][0], figure=fig, cmap=plt.cm.gist_rainbow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW47wcFUcxRx"
      },
      "source": [
        "**Note**: to use the kwyk models the input image dimension should be (256, 256, 256). if your image dimension is not as mentioned, use the `nibabel.processing.conform` function to conform it to the 256 block size. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKMg_6hmapOA"
      },
      "source": [
        "# Load pre-trained model\n",
        "\n",
        "Use datalad to retrieve the kwyk trained models. there are 3 options to use:\n",
        "\n",
        "1. Spike-and-slab dropout (bvwn_multi_prior)\n",
        "2. MC Bernoulli dropout (bwn_multi)\n",
        "3. MAP (bwn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vxgit3xK_x3"
      },
      "source": [
        "!datalad clone https://github.com/neuronets/trained-models && \\\n",
        "  cd trained-models && git-annex enableremote osf-storage && \\\n",
        "  datalad get -s osf-storage neuronets/kwyk/0.4.1/all_50_bvwn_multi_prior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YDBdqaHbtUE"
      },
      "source": [
        "Here we use the model with Spike-and-slab dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z7MVxU_LRbF"
      },
      "source": [
        "model_path = \"trained-models/neuronets/kwyk/0.4.1/all_50_bvwn_multi_prior/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUr024ibLXta"
      },
      "source": [
        "batch_size = 2\n",
        "volume_shape = (256, 256, 256)\n",
        "block_shape = (32, 32, 32) # Do not change as this version of the model was trained on this block size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n_2vgUVcUNs"
      },
      "source": [
        "# Predict from the sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWwKabgCLbEJ"
      },
      "source": [
        "from nobrainer.volume import standardize\n",
        "from nobrainer.prediction import predict_by_estimator\n",
        "import nibabel as nib\n",
        "\n",
        "image_path = evaluate_paths[0][0]\n",
        "out,variance, entropy = predict_by_estimator(image_path, \n",
        "                                              model_path,\n",
        "                                              block_shape = block_shape,\n",
        "                                              batch_size = batch_size,\n",
        "                                              normalizer = standardize,\n",
        "                                              n_samples=2,\n",
        "                                              return_variance=True,\n",
        "                                              return_entropy=True,\n",
        "                                              )\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYxgErKcLqGl"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "plotting.plot_roi(out, bg_img=image_path, alpha=0.4, figure=fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4tBZuLwOCUa"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "plotting.plot_roi(variance, bg_img=image_path, threshold=0.001, figure=fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ILgzv7NOHeM"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "plotting.plot_roi(entropy, bg_img=image_path, threshold=0.001, figure=fig)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
